{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "McAllister_CNN_Train_and_Test.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Ro4WGz4xXZjp",
        "J-0Yt6xhsahE",
        "sb6pBr9Ds9Mj",
        "xoozqZdfMiF9",
        "aRKoJPHvnoD2",
        "aJTWDEsaQl0D"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ro4WGz4xXZjp"
      },
      "source": [
        "### Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcqPbg9AXZjy"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-0Yt6xhsahE"
      },
      "source": [
        "### Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIjiVPM9uwgy"
      },
      "source": [
        "#Install MRI File Managers\n",
        "!pip install nibabel\n",
        "!pip install nilearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import my packages\n",
        "import sys\n",
        "sys.path.append('/content/gdrive/MyDrive/Colab Notebooks/Additional Function Scripts')\n",
        "\n",
        "import process_nii\n",
        "import cnn_model"
      ],
      "metadata": {
        "id": "U9ibtQzOUsOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Z7yDA0qsahI"
      },
      "source": [
        "#Import other Packages\n",
        "from google.colab import drive\n",
        "\n",
        "import math\n",
        "from statistics import mean, stdev\n",
        "import time\n",
        "import cv2\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import itertools\n",
        "from pathlib import Path\n",
        "import nibabel\n",
        "import nilearn\n",
        "from nilearn import image\n",
        "from nilearn.image import resample_img\n",
        "\n",
        "import numpy as np\n",
        "from os import listdir\n",
        "from os.path import join, basename, isdir\n",
        "import sklearn.metrics\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, classification_report\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.utils import shuffle, class_weight\n",
        "from skimage.color import gray2rgb\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tqdm.notebook import trange, tqdm, tqdm_notebook\n",
        "import scipy\n",
        "import h5py\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from matplotlib import pyplot, cm\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "from nibabel.testing import data_path\n",
        "\n",
        "from numpy.random import seed\n",
        "seed(2018)\n",
        "import random\n",
        "random.seed(2018)\n",
        "tf.random.set_seed(2018)\n",
        "\n",
        "import keras\n",
        "from collections import Counter\n",
        "from keras.layers import Dense, Input\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers.core import Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPool2D, LSTM, Conv3D, MaxPool3D, Conv1D, MaxPool1D, concatenate\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras import initializers, optimizers, losses, regularizers\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.decomposition import PCA, IncrementalPCA\n",
        "from keras import backend as K\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqNi0N4HsnqT"
      },
      "source": [
        "### Import, Resize, and Create Training Data Sets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visual, Sensorimotor, Salience, Language, FrontoParietal, DorsalAttention, DefaultMode, Cerebellar, 4painBest, 8Best\n",
        "channel = \"8Best\"\n",
        "\n",
        "# 30ICA, 42ICA\n",
        "ICA_type = \"42ICA\"\n",
        "\n",
        "#s2D, VGG16, VGG19, ResNet\n",
        "model_type = \"s2D\""
      ],
      "metadata": {
        "id": "1AxDUTeoPewx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Resize Files\n",
        "\n",
        "#Affine = Detail of images (Higher = less detailed, Lower = more detailed, Normal = 2)\n",
        "affine_value = 3\n",
        "\n",
        "%cd /content/gdrive/MyDrive/MRI Data/JamesCNN/{channel}/{ICA_type}/training/Painful\n",
        "train_painful_scans_resized = np.array([process_nii.resize_5D_to_4D(file_,affine_value) for file_ in os.listdir() if \".nii\" in file_])\n",
        "#train_painful_scans_resized = np.array([process_nii.resize(file_,affine_value) for file_ in os.listdir() if \".nii\" in file_])\n",
        "\n",
        "%cd /content/gdrive/MyDrive/MRI Data/JamesCNN/{channel}/{ICA_type}/training/notPainful\n",
        "train_painless_scans_resized = np.array([process_nii.resize_5D_to_4D(file_,affine_value) for file_ in os.listdir() if \".nii\" in file_])\n",
        "#train_painless_scans_resized = np.array([process_nii.resize(file_,affine_value) for file_ in os.listdir() if \".nii\" in file_])"
      ],
      "metadata": {
        "id": "zByvOZFXfK6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzjPD3OIsnqU"
      },
      "source": [
        "#Create Training Data Sets\n",
        "x_train, y_train = process_nii.create_training_set(train_painful_scans_resized, train_painless_scans_resized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sb6pBr9Ds9Mj"
      },
      "source": [
        "### Define Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUmbxDHDs9Mj"
      },
      "source": [
        "def load_hyperparameters():\n",
        "\n",
        "  nEpochs = 50\n",
        "  batch_size = 16\n",
        "  callback = tf.keras.callbacks.EarlyStopping(monitor=\"loss\", patience=3)\n",
        "  k_fold_num = 5\n",
        "  k_fold = StratifiedKFold(n_splits = k_fold_num, shuffle=True)\n",
        "  METRICS = [\n",
        "              keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "              keras.metrics.AUC(name='auc'),\n",
        "              keras.metrics.Precision(name='precision'),\n",
        "              keras.metrics.Recall(name='recall'),\n",
        "              keras.metrics.TruePositives(name='tp'),\n",
        "              keras.metrics.FalsePositives(name='fp'),\n",
        "              keras.metrics.TrueNegatives(name='tn'),\n",
        "              keras.metrics.FalseNegatives(name='fn'),\n",
        "            ]\n",
        "  #class_weights = class_weight.compute_class_weight('balanced',np.unique(y_train), y_train)\n",
        "  class_weights = {0:0.74166667, \n",
        "                   1:1.53448276}\n",
        "\n",
        "  return nEpochs, batch_size, callback, k_fold, METRICS, class_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoozqZdfMiF9"
      },
      "source": [
        "### Train 2D CNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Display metrics per fold? (LOTS OF OUTPUT!)\n",
        "view_metrics_per_fold = False\n",
        "\n",
        "#Load Hyperparameters\n",
        "nEpochs, batch_size, callback, k_fold, metrics, class_weights = load_hyperparameters()\n",
        "\n",
        "#Prep result lists\n",
        "loss_per_fold = []\n",
        "acc_per_fold = []\n",
        "auc_per_fold = []\n",
        "preci_per_fold = []\n",
        "recall_per_fold = []\n",
        "tp_per_fold = []\n",
        "fp_per_fold = []\n",
        "tn_per_fold = []\n",
        "fn_per_fold = []\n",
        "fold_no = 1\n",
        "\n",
        "print(\"The shape of the current training set is\", x_train.shape,\"and contains\",y_train.tolist().count(1),\"painful and\",y_train.tolist().count(0),\"painless patients.\\n\")\n",
        "\n",
        "for train, test in k_fold.split(x_train, y_train):\n",
        "\n",
        "  model = cnn_model.s2D(x_train[train], y_train[train], batch_size, nEpochs, callback, metrics, class_weights)\n",
        "  #model = cnn_model.VGG16(x_train[train], y_train[train], batch_size, nEpochs, callback, metrics, class_weights)\n",
        "  #model = cnn_model.VGG19(x_train[train], y_train[train], batch_size, nEpochs, callback, metrics, class_weights)\n",
        "  #model = cnn_model.ResNet(x_train[train], y_train[train], batch_size, nEpochs, callback, metrics, class_weights)\n",
        "\n",
        "  scores = model.evaluate(x_train[test], y_train[test], verbose=1)\n",
        "  \n",
        "  if view_metrics_per_fold:\n",
        "    print(f'Score for fold {fold_no}:\\n{model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]}; {model.metrics_names[2]} of {scores[2]}; {model.metrics_names[3]} of {scores[3]}; {model.metrics_names[4]} of {scores[4]}; {model.metrics_names[5]} of {scores[5]}; {model.metrics_names[6]} of {scores[6]}; {model.metrics_names[7]} of {scores[7]}; {model.metrics_names[8]} of {scores[8]}')   \n",
        "  \n",
        "  loss_per_fold.append(scores[0])\n",
        "  acc_per_fold.append(scores[1])\n",
        "  auc_per_fold.append(scores[2])\n",
        "  preci_per_fold.append(scores[3])\n",
        "  recall_per_fold.append(scores[4])\n",
        "  tp_per_fold.append(scores[5])\n",
        "  fp_per_fold.append(scores[6])\n",
        "  tn_per_fold.append(scores[7])\n",
        "  fn_per_fold.append(scores[8])\n",
        "\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "#Print average scores for all folds\n",
        "print(\"\\n\")\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold)} (± {np.std(acc_per_fold)})')\n",
        "print(f'> AUC: {np.mean(auc_per_fold)} (± {np.std(auc_per_fold)})')\n",
        "print(f'> PRECISION: {np.mean(preci_per_fold)} (± {np.std(preci_per_fold)})')\n",
        "print(f'> RECALL: {np.mean(recall_per_fold)} (± {np.std(recall_per_fold)})')\n",
        "print(f'> TP: {np.mean(tp_per_fold)} (± {np.std(tp_per_fold)})')\n",
        "print(f'> FP: {np.mean(fp_per_fold)} (± {np.std(fp_per_fold)})')\n",
        "print(f'> TN: {np.mean(tn_per_fold)} (± {np.std(tn_per_fold)})')\n",
        "print(f'> FN: {np.mean(fn_per_fold)} (± {np.std(fn_per_fold)})')\n",
        "print('------------------------------------------------------------------------')"
      ],
      "metadata": {
        "id": "fOW5awD3ih3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRKoJPHvnoD2"
      },
      "source": [
        "### Save Training Data to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/MRI Data/JamesCNN/{channel}/{ICA_type}/Results\n",
        "\n",
        "#Save the model\n",
        "model.save(\"{}_CNN_{}_AFFINE_VALUE_{}.h5\".format(model_type,ICA_type,affine_value))\n",
        "\n",
        "#Save metrics for all folds as csv\n",
        "results = pd.DataFrame(columns=model.metrics_names)\n",
        "results['loss'] = loss_per_fold\n",
        "results['accuracy'] = acc_per_fold\n",
        "results['auc'] = auc_per_fold\n",
        "results['precision'] = preci_per_fold\n",
        "results['recall'] = recall_per_fold\n",
        "results['tp'] = tp_per_fold\n",
        "results['fp'] = fp_per_fold\n",
        "results['tn'] = tn_per_fold\n",
        "results['fn'] = fn_per_fold\n",
        "results.index += 1 \n",
        "results.to_csv(\"TRAIN_METRICS_ALL_FOLDS_{}_CNN_{}_AFFINE_VALUE_{}.csv\".format(model_type,ICA_type,affine_value))\n",
        "\n",
        "#Save average scores (± std) for folds as csv\n",
        "results = pd.DataFrame(columns=model.metrics_names)\n",
        "results['loss'] = [np.mean(loss_per_fold), (\"± \"+ str(np.std(loss_per_fold)))]\n",
        "results['accuracy'] = [np.mean(acc_per_fold), (\"± \"+ str(np.std(acc_per_fold)))]\n",
        "results['auc']= [np.mean(auc_per_fold), (\"± \"+ str(np.std(auc_per_fold)))]\n",
        "results['precision'] = [np.mean(preci_per_fold), (\"± \"+ str(np.std(preci_per_fold)))]\n",
        "results['recall'] = [np.mean(recall_per_fold), (\"± \"+ str(np.std(recall_per_fold)))]\n",
        "results['tp']= [np.mean(tp_per_fold), (\"± \"+ str(np.std(tp_per_fold)))]\n",
        "results['fp'] = [np.mean(fp_per_fold), (\"± \"+ str(np.std(fp_per_fold)))]\n",
        "results['tn'] = [np.mean(tn_per_fold), (\"± \"+ str(np.std(tn_per_fold)))]\n",
        "results['fn'] = [np.mean(fn_per_fold), (\"± \"+ str(np.std(fn_per_fold)))]\n",
        "results.index += 1 \n",
        "results.to_csv(\"TRAIN_AVERAGE_FOLD_METRICS_{}_CNN_{}_AFFINE_VALUE_{}.csv\".format(model_type,ICA_type,affine_value))"
      ],
      "metadata": {
        "id": "9tB1um4znoD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJTWDEsaQl0D"
      },
      "source": [
        "### 2D External Validation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Resize Files\n",
        "%cd /content/gdrive/MyDrive/MRI Data/JamesCNN/{channel}/{ICA_type}/testing/Painful\n",
        "test_painful_scans_resized = np.array([process_nii.resize_5D_to_4D(file_,affine_value) for file_ in os.listdir() if \".nii\" in file_])\n",
        "#test_painful_scans_resized = np.array([process_nii.resize(file_,affine_value) for file_ in os.listdir() if \".nii\" in file_])\n",
        "\n",
        "%cd /content/gdrive/MyDrive/MRI Data/JamesCNN/{channel}/{ICA_type}/testing/notPainful\n",
        "test_painless_scans_resized = np.array([process_nii.resize_5D_to_4D(file_,affine_value) for file_ in os.listdir() if \".nii\" in file_])\n",
        "#test_painless_scans_resized = np.array([process_nii.resize(file_,affine_value) for file_ in os.listdir() if \".nii\" in file_])\n",
        "\n",
        "#Create Test Data Sets\n",
        "x_test, y_test = process_nii.create_test_set(test_painful_scans_resized, test_painless_scans_resized)"
      ],
      "metadata": {
        "id": "vvLlEEv1hMSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNqKJdiUQl0N"
      },
      "source": [
        "#Reset metric lists for each slice\n",
        "loss_per_fold = []\n",
        "acc_per_fold = []\n",
        "auc_per_fold = []\n",
        "preci_per_fold = []\n",
        "recall_per_fold = []\n",
        "tp_per_fold = []\n",
        "fp_per_fold = []\n",
        "tn_per_fold = []\n",
        "fn_per_fold = []\n",
        "\n",
        "#Load the model in question\n",
        "%cd /content/gdrive/MyDrive/MRI Data/JamesCNN/{channel}/{ICA_type}/Results\n",
        "for file_ in os.listdir():\n",
        "  if \".h5\" in file_:\n",
        "    print(\"\\nLoading\",file_,\"\\n\")\n",
        "    \n",
        "    model = keras.models.load_model(file_)\n",
        "\n",
        "    print(\"The shape of the current testing set is:\", x_test.shape,\"and contains\",y_test.tolist().count(1),\"painful and\",y_test.tolist().count(0),\"painless patients\")\n",
        "    scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "\n",
        "    loss_per_fold.append(scores[0])\n",
        "    acc_per_fold.append(scores[1])\n",
        "    auc_per_fold.append(scores[2])\n",
        "    preci_per_fold.append(scores[3])\n",
        "    recall_per_fold.append(scores[4])\n",
        "    tp_per_fold.append(scores[5])\n",
        "    fp_per_fold.append(scores[6])\n",
        "    tn_per_fold.append(scores[7])\n",
        "    fn_per_fold.append(scores[8])\n",
        "\n",
        "    #Save metrics for all folds as csv\n",
        "    results = pd.DataFrame(columns=model.metrics_names)\n",
        "\n",
        "    results['loss'] = loss_per_fold\n",
        "    results['accuracy'] = acc_per_fold\n",
        "    results['auc'] = auc_per_fold\n",
        "    results['precision'] = preci_per_fold\n",
        "    results['recall'] = recall_per_fold\n",
        "    results['tp'] = tp_per_fold\n",
        "    results['fp'] = fp_per_fold\n",
        "    results['tn'] = tn_per_fold\n",
        "    results['fn'] = fn_per_fold\n",
        "    results['sensitivity'] = tp_per_fold[0] / (tp_per_fold[0] + fn_per_fold[0])\n",
        "    results['specificity'] = tn_per_fold[0] / (tn_per_fold[0] + fp_per_fold[0])\n",
        "    results.index += 1 \n",
        "    results.to_csv(\"TEST_{}_CNN_AFFINE_VALUE_{}.csv\".format(model_type,affine_value))  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}